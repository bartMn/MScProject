{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from itertools import product\n",
    "\n",
    "module_path = os.path.abspath(os.path.join(f\"..{os.sep}src\"))\n",
    "#module_path = os.path.join(module_path, f\"..\")\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from data.data_read import singleSampleDataset, test_single_samples\n",
    "from ml.simple_model import ModelClass, twoCamsModelClass, multiModalClass#, fiveDepthCamsModel, depthAndAllFrankaDataModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = os.path.abspath(os.path.join(f\"..{os.sep}results\"))\n",
    "\n",
    "print(\"training model 0...\")\n",
    "cam0_rgb_model = ModelClass(batch_size= 64, epochs_num = 15, save_path= os.path.join(results_dir, \"cam0_rgb_model\"), input_data_keys= [\"cam0_rgb\"])\n",
    "cam0_rgb_model.init_model()\n",
    "cam0_rgb_model.train_model()\n",
    "print(\"training model0 finished\")\n",
    "\n",
    "\n",
    "print(\"training model 1...\")\n",
    "twoCamsModel = twoCamsModelClass(batch_size= 64, epochs_num = 15, save_path= os.path.join(results_dir, \"twoCamsModel\"), input_data_keys = [\"cam0_rgb\", \"cam1_rgb\"])\n",
    "twoCamsModel.init_model()\n",
    "twoCamsModel.train_model()\n",
    "print(\"training model 1 finished\")\n",
    "\n",
    "\n",
    "input_data_keys_dict = {\"fiveDepthCamsModel\": [\"cam0_depth\", \"cam1_depth\", \"cam2_depth\", \"cam3_depth\", \"cam4_depth\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"rgb2\": [\"cam1_rgb\", \"cam2_rgb\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"depth2\": [\"cam1_depth\", \"cam2_depth\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"frankaDataOnly\": [\"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"rgb2depth2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_depth\", \"cam2_depth\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"rgb2flow2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_flow\", \"cam2_flow\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"depth2flow2\": [\"cam1_depth\", \"cam2_depth\", \"cam1_flow\", \"cam2_flow\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"rgb2depth2flow2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_depth\", \"cam2_depth\", \"cam1_flow\", \"cam2_flow\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \n",
    "\n",
    "                        \"fiveDepthCamsModel\": [\"cam0_depth\", \"cam1_depth\", \"cam2_depth\", \"cam3_depth\", \"cam4_depth\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"rgb2\": [\"cam1_rgb\", \"cam2_rgb\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"depth2\": [\"cam1_depth\", \"cam2_depth\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"frankaDataOnly\": [\"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"rgb2depth2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_depth\", \"cam2_depth\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"rgb2flow2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_flow\", \"cam2_flow\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"depth2flow2\": [\"cam1_depth\", \"cam2_depth\", \"cam1_flow\", \"cam2_flow\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"rgb2depth2flow2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_depth\", \"cam2_depth\", \"cam1_flow\", \"cam2_flow\", \"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \n",
    "                        \"noActionsfiveDepthCamsModel\": [\"cam0_depth\", \"cam1_depth\", \"cam2_depth\", \"cam3_depth\", \"cam4_depth\" , \"franka_forces\", \"franka_state\"],\n",
    "                        \"noActionsrgb2\": [\"cam1_rgb\", \"cam2_rgb\" , \"franka_forces\", \"franka_state\"],\n",
    "                        \"noActionsdepth2\": [\"cam1_depth\", \"cam2_depth\" , \"franka_forces\", \"franka_state\"],\n",
    "                        \"noActionsfrankaDataOnly\": [\"franka_actions\", \"franka_forces\", \"franka_state\"],\n",
    "                        \"noActionsrgb2depth2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_depth\", \"cam2_depth\" , \"franka_forces\", \"franka_state\"],\n",
    "                        \"noActionsrgb2flow2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_flow\", \"cam2_flow\" , \"franka_forces\", \"franka_state\"],\n",
    "                        \"noActionsdepth2flow2\": [\"cam1_depth\", \"cam2_depth\", \"cam1_flow\", \"cam2_flow\" , \"franka_forces\", \"franka_state\"],\n",
    "                        \"noActionsrgb2depth2flow2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_depth\", \"cam2_depth\", \"cam1_flow\", \"cam2_flow\" , \"franka_forces\", \"franka_state\"],\n",
    "                        \n",
    "\n",
    "                        \"noFrankaDatafiveDepthCamsModel\": [\"cam0_depth\", \"cam1_depth\", \"cam2_depth\", \"cam3_depth\", \"cam4_depth\"],\n",
    "                        \"noFrankaDatargb2\": [\"cam1_rgb\", \"cam2_rgb\"],\n",
    "                        \"noFrankaDatadepth2\": [\"cam1_depth\", \"cam2_depth\"],\n",
    "                        \"noFrankaDatargb2depth2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_depth\", \"cam2_depth\"],\n",
    "                        \"noFrankaDatargb2flow2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_flow\", \"cam2_flow\"],\n",
    "                        \"noFrankaDatadepth2flow2\": [\"cam1_depth\", \"cam2_depth\", \"cam1_flow\", \"cam2_flow\"],\n",
    "                        \"noFrankaDatargb2depth2flow2\": [\"cam1_rgb\", \"cam2_rgb\", \"cam1_depth\", \"cam2_depth\", \"cam1_flow\", \"cam2_flow\"]\n",
    "                        }\n",
    "\n",
    "for model_name in input_data_keys_dict:\n",
    "    fiveDepthCamsModel = multiModalClass(batch_size= 64, epochs_num = 15, save_path= os.path.join(results_dir, model_name), input_data_keys = input_data_keys_dict[model_name])\n",
    "    fiveDepthCamsModel.init_model(learning_rate=0.001, input_data_keys = input_data_keys_dict[model_name])\n",
    "    \n",
    "    print(f\"training model {model_name}...\")\n",
    "    fiveDepthCamsModel.train_model()\n",
    "    print(f\"training {model_name} finished\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "\n",
    "results_path = os.path.join(os.getcwd(), \"../results\")\n",
    "scores_dir = dict()\n",
    "\n",
    "#Extracting accuracy and accuracy, F1 and loss from all tested hyperparameters\n",
    "for model in os.listdir(results_path):\n",
    "    folder = os.path.join(results_path, model)\n",
    "    if os.path.isdir(folder):\n",
    "        #print(model)\n",
    "        file_path = os.path.join(folder, \"best_valid_loss.txt\")\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            \n",
    "            # Extract accuracy and accuracy, F1 and loss score using regular expressions\n",
    "            accuracy_match = re.search(r\"best validation epoch num (in m): (\\d+\\.\\d+)\", lines[1])\n",
    "\n",
    "            try:\n",
    "                mse = float(accuracy_match.group(1))\n",
    "                scores_dir[model] = {\"mse\": mse}\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "\n",
    "#sorting models hyperparameters accornig to scores\n",
    "sorted_acc_dict = dict(sorted(scores_dir.items(), key=lambda x: x[1][\"mse\"], reverse=False))\n",
    "\n",
    "#printing sorted model hyperparamaters\n",
    "print(100*\"~\")\n",
    "print(\"#\"*20 +\"\\tBEST MODELS (MSE)\\t\" + \"#\"*20)\n",
    "print(100*\"~\")\n",
    "for i, model in enumerate(sorted_acc_dict):\n",
    "    print(f\"model: {model},\\t mse = {sorted_acc_dict[model]['mse']},\")  \n",
    "\n",
    "print(100*\"~\")\n",
    "\n",
    "#saving sorted model hyperparamaters to a file  \n",
    "with open(\"sorted_models.txt\", \"w\") as file:\n",
    "    file.write(100*\"~\" + \"\\n\")\n",
    "    file.write(\"#\"*20 +\"\\tBEST MODELS (MSE)\\t\" + \"#\"*20 + \"\\n\")\n",
    "    file.write(100*\"~\" + \"\\n\")\n",
    "    for i, model in enumerate(sorted_acc_dict):\n",
    "        file.write(f\"model: {model},\\t mse = {sorted_acc_dict[model]['mse']}\\n\")  \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "isaac_env2_ub",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
